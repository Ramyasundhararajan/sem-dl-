{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3304464,"sourceType":"datasetVersion","datasetId":1998782},{"sourceId":3551029,"sourceType":"datasetVersion","datasetId":1946928}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#a.\nimport numpy as np\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.models import Model\nfrom keras.layers import Dense, Flatten\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\n\n# Load the dataset\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# Load the VGG16 model without the top fully connected layers\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n\n# Add custom layers on top of the base model\nx = Flatten()(base_model.output)\nx = Dense(256, activation='relu')(x)\npredictions = Dense(10, activation='softmax')(x)\n\n# Define the complete model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze the base model layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Preprocess the data\nx_train = preprocess_input(x_train)\nx_test = preprocess_input(x_test)\n\n# Create data generators for data augmentation\ndatagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\ndatagen.fit(x_train)\n\n# Train the model\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nmodel.fit(datagen.flow(x_train, y_train, batch_size=32), validation_data=(x_test, y_test), epochs=1, callbacks=[early_stopping])\n\n# Evaluate the model on test data\ntest_loss, test_accuracy = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T16:35:51.664544Z","iopub.execute_input":"2024-10-18T16:35:51.665036Z","iopub.status.idle":"2024-10-18T16:43:19.354732Z","shell.execute_reply.started":"2024-10-18T16:35:51.664989Z","shell.execute_reply":"2024-10-18T16:43:19.353201Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 215ms/step - accuracy: 0.4740 - loss: 3.2442 - val_accuracy: 0.6164 - val_loss: 1.1291\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 169ms/step - accuracy: 0.6166 - loss: 1.1322\nTest Accuracy: 61.64%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"b. ImageNet Classification with Deep Residual networks (ResNet)","metadata":{}},{"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nimport numpy as np\n\n# Load the pre-trained ResNet50 model\nmodel = ResNet50(weights='imagenet')\n\n# Load an image file that contains an image to be classified\nimg_path = '/kaggle/input/resnet50-indoor-object-detection/DATASET/test/Meja (354).jpg'  # Replace with the path to your image\nimg = image.load_img(img_path, target_size=(224, 224))\n\n# Convert the image to a numpy array\nx = image.img_to_array(img)\n\n# Add a batch dimension (since the model expects a batch of images)\nx = np.expand_dims(x, axis=0)\n\n# Preprocess the input image for the model\nx = preprocess_input(x)\n\n# Predict the class of the image\npredictions = model.predict(x)\n\n# Decode the top 3 predictions into human-readable class names\nprint('Predicted:', decode_predictions(predictions, top=3)[0])\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T16:51:31.929743Z","iopub.execute_input":"2024-10-18T16:51:31.930220Z","iopub.status.idle":"2024-10-18T16:51:35.876165Z","shell.execute_reply.started":"2024-10-18T16:51:31.930180Z","shell.execute_reply":"2024-10-18T16:51:35.874905Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\nDownloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nPredicted: [('n02727426', 'apiary', 0.44437236), ('n03992509', \"potter's_wheel\", 0.1255737), ('n02797295', 'barrow', 0.119712114)]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"c. Classifying Species of Flowers using Transfer Learning","metadata":{}},{"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nimport numpy as np\n\n# Load the pre-trained ResNet50 model\nmodel = ResNet50(weights='imagenet')\n\n# Load an image file that contains an image to be classified\nimg_path = '/kaggle/input/flowers/flowers/astilbe/10091895024_a2ea04cda6_c.jpg'  # Replace with your image path\nimg = image.load_img(img_path, target_size=(224, 224))\n\n# Convert the image to a numpy array\nx = image.img_to_array(img)\n\n# Add a batch dimension\nx = np.expand_dims(x, axis=0)\n\n# Preprocess the input image\nx = preprocess_input(x)\n\n# Predict the class of the image\npredictions = model.predict(x)\n\n# Decode and print the top 3 predicted classes with their probabilities\nprint('Predicted:', decode_predictions(predictions, top=3)[0])\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T16:53:39.202174Z","iopub.execute_input":"2024-10-18T16:53:39.203305Z","iopub.status.idle":"2024-10-18T16:53:43.260754Z","shell.execute_reply.started":"2024-10-18T16:53:39.203226Z","shell.execute_reply":"2024-10-18T16:53:43.259542Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\nPredicted: [('n11879895', 'rapeseed', 0.31405503), ('n04604644', 'worm_fence', 0.0876353), ('n02793495', 'barn', 0.06969871)]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}